{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no daal4py\n"
     ]
    }
   ],
   "source": [
    "#import sys\n",
    "#sys.path.append(os.path.abspath('..'))#sys.path[0] + '/..') \n",
    "from vb_estimators import  LinRegSupreme,LinSVR,RBFSVR,ENet,L1Lars,GBR,HGBR,FlexiblePipe\n",
    "from vb_helper import VBHelper\n",
    "from vb_cross_validator import regressor_q_stratified_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup the experiment/project\n",
    "#### note the 'run_stacked' kwarg that can be set to create the stacked_regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridpoints=5\n",
    "kwargs=dict(\n",
    "    run_stacked=True,\n",
    "    test_share=0,#keep at 0 for small datasets\n",
    "    cv_folds=5,\n",
    "    cv_reps=10,\n",
    "    #cv_groupcount=5,\n",
    "    cv_strategy=('quantile',5), # for stratified cv\n",
    "    random_state=2 # random_state for reproducibility\n",
    ")\n",
    "vbhelper=VBHelper(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer_list=['neg_mean_squared_error', 'neg_mean_absolute_error', 'r2'] #cross_validate wants strings\n",
    "vbhelper.scorer_list=scorer_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### User Import Dataset Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['STA_ID', 'LONG', 'LAT', 'OrigHabCode', 'Date', 'THG_Fish', 'YEAR', 'SEASON', 'SUBAREA', 'HABCODE', 'Floc_Depth_ft', 'AFDW_Floc', 'MEHG_Floc', 'THG_floc', 'Tot_Phos_floc', 'Bulk_Dens_Floc', 'Soil_Thickness_FT', 'AFDW_Soil', 'Bulk_Dens_Soil', 'PH_soil', 'SO4_soil', 'MEHG_soil', 'THG_soil', 'Tot_Carbon_Soil_%', 'Tot_Nitrogen_Soil_%', 'Tot_Phos_soil', 'Wat_Depth_ft', 'COND_SW', 'DO_SW', 'TEMP_SW', 'PH_SW', 'TURB_SW', 'REDOX_SW', 'Alk_Phos_SW', 'CHLA_SW', 'CL_SW', 'MEHG_SW', 'NH4_SW', 'NO2_SW', 'NO3_SW', 'SO4_SW', 'Sol_Reac_Phos_SW', 'THG_SW', 'TOC_SW', 'Tot_Nitrogen_SW', 'Tot_Phos_SW', 'REDOX_PW', 'H2S_PW', 'Sol_Reac_Phos_PW', 'MEHG_Peri_AVG', 'THG_epi_peri']\n"
     ]
    }
   ],
   "source": [
    "data_path=os.path.join('sample_data','ex1.csv')\n",
    "df=pd.read_csv(data_path)\n",
    "all_vars=list(df.columns)\n",
    "print(all_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### user has option to specify \"regulatory standard\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The user sets the variables to use for x and y.\n",
    "y_name='THG_Fish'\n",
    "loc_vars=['LAT','LONG']\n",
    "drop_vars=['Date','OrigHabCode','STA_ID']\n",
    "drop_vars.extend(loc_vars)\n",
    "drop_vars.append(y_name)\n",
    "x_vars=[var for var in all_vars if var not in drop_vars]\n",
    "X_df=df.loc[:,x_vars]\n",
    "y_df=df.loc[:,y_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "shuf=np.arange(y_df.shape[0])\n",
    "seed=0\n",
    "rng = np.random.default_rng(seed)\n",
    "rng.shuffle(shuf)\n",
    "X_df=X_df.iloc[shuf]\n",
    "y_df=y_df.iloc[shuf]\n",
    "vbhelper.setData(X_df,y_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup the analytical pipelines\n",
    "#### note the inner_cv_dict and prep_dict that are used to consolidate vb_estimator kwargs and to facilitate the divison between prep and post steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_cv_dict={'cv_reps':1,'cv_folds':5,'cv_strategy':('quantile',5)}\n",
    "inner_cv=vbhelper.getCV(cv_dict=inner_cv_dict)\n",
    "\n",
    "prep_dict={'impute_strategy':'impute_knn5','cat_idx':vbhelper.cat_idx}\n",
    "\n",
    "pipe_kwargs=dict(do_prep=not vbhelper.run_stacked,prep_dict=prep_dict,inner_cv=inner_cv,gridpoints=gridpoints,cat_idx=vbhelper.cat_idx,float_idx=vbhelper.float_idx,bestT=False)\n",
    "pipe_dict={\n",
    "    'gradient-boosting-reg':{'pipe':GBR,'pipe_kwargs':dict(\n",
    "        prep_dict=prep_dict,do_prep=not vbhelper.run_stacked)},\n",
    "    #'lin-reg-supreme':{'pipe':LinRegSupreme,'pipe_kwargs':pipe_kwargs}, \n",
    "    #'powXB-least-sq':{'pipe':FlexiblePipe,'pipe_kwargs':{**pipe_kwargs,'flex_kwargs':{'form':'powXB'}}}),\n",
    "    #'expXB-least-sq':{'pipe':FlexiblePipe,'pipe_kwargs':{**pipe_kwargs,'flex_kwargs':{'form':'expXB'}}}), #expXB is default\n",
    "    #'nonlinear-search-least-sq': {'pipe':FlexiblePipe,'pipe_kwargs':{**pipe_kwargs,'functional_form_search':True}},\n",
    "    #'robust-powXB-least-sq':{'pipe':FlexiblePipe,'pipe_kwargs':{**pipe_kwargs,'flex_kwargs':{'form':'powXB','robust':True}}},\n",
    "    #'robust-expXB-least-sq':{'pipe':FlexiblePipe,'pipe_kwargs':{**pipe_kwargs,'flex_kwargs':{'form':'expXB','robust':True}}}, #expXB is default\n",
    "    #'robust-nonlinear-search-least-sq': {'pipe':FlexiblePipe,'pipe_kwargs':{**pipe_kwargs,'functional_form_search':True,'flex_kwargs':{'robust':True}}},\n",
    "    #'histogram-gradient-boosting-reg':{'pipe':HGBR,'pipe_kwargs':{'prep_dict':{'cat_idx':vbhelper.cat_idx}}},\n",
    "    \n",
    "    \n",
    "    #'elastic-net':{'pipe':ENet,'pipe_kwargs':pipe_kwargs}, \n",
    "    #'linear-svr-cv':{'pipe':LinSVR,'pipe_kwargs':pipe_kwargs}\n",
    "    'rbf-svr-cv':{'pipe':RBFSVR,'pipe_kwargs':pipe_kwargs}, \n",
    "    'lassolars':{'pipe':L1Lars,'pipe_kwargs':pipe_kwargs},\n",
    "    }\n",
    "\n",
    "\n",
    "#estimator_dict={'multi_pipe':{'pipe':MultiPipe(pipelist=[(k,v) for k,v in estimator_dict.items()],cat_idx=vbhelper.cat_idx)}\n",
    "vbhelper.setPipeDict(pipe_dict) #formerly setEstimatorDict\n",
    "vbhelper.setModelDict()\n",
    "#vbhelper.model_dict={key:val() for key,val in vbhelper.estimator_dict.items()} # they will be models once .fit is called"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create a smaller test run to check runtime, debug, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test=train_test_split(X_df,y_df,test_size=0.5) #just for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi_pipe\n",
      "train R2: 0.6548172426859309\n",
      "test R2: 0.44104404324682167\n",
      "runtime:0.8291618426640829 min.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "runtest=True\n",
    "if runtest:\n",
    "    for name,est in vbhelper.model_dict.items():\n",
    "        start=time()\n",
    "        print(name)\n",
    "        est.fit(X_train,y_train)\n",
    "        print('train R2:',est.score(X_train,y_train))\n",
    "        if not X_test is None:print('test R2:',est.score(X_test,y_test))\n",
    "        end=time()\n",
    "        print(f'runtime:{(end-start)/60} min.\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40406269819818386\n",
      "0.31684028211570825\n",
      "0.37384949685447544\n"
     ]
    }
   ],
   "source": [
    "if vbhelper.run_stacked and runtest:\n",
    "    mp=vbhelper.model_dict['multi_pipe']\n",
    "    fitted_ipipe_dict=mp.build_individual_fitted_pipelines()\n",
    "    print(fitted_ipipe_dict['lassolars'].score(X_test,y_test))\n",
    "    print(fitted_ipipe_dict['gradient-boosting-reg'].score(X_test,y_test))\n",
    "    print(fitted_ipipe_dict['rbf-svr-cv'].score(X_test,y_test))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-13-60215a10e730>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-60215a10e730>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    -\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### end small test-run debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Fit the final models for all estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vbhelper.runCrossValidate(try_load=True) #try_load speeds things up by reloading results if they've been run before with same setup and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vbhelper.fitFinalModelDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot cv_yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### graphs and table to summarize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vbhelper.buildCVScoreDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vbhelper.cv_score_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vbhelper.viewCVScoreDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vbhelper.predictCVYhat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vbhelper.jsonifyProjectCVResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vbhelper.cv_score_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vbhelper.pickleSelf() #for development in other notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vbhelper.plotCVScores(sort=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vbhelper.plotCVYhatVsY(regulatory_standard=False,decision_criteria=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add table of results for the pipelines, coefficients, stats, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vbhelper.plotCVYhat(single_plot=True) \n",
    "# make Y line faint and make dots at actual values\n",
    "# add the mean of each series and make more visible\n",
    "# sort by original row order or by increasing value of Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vbhelper.plotCVYhat(single_plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensitivity analysis of rows\n",
    "Outlier plots\n",
    "DfFits, leverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensitivity analysis of columns/features\n",
    "#### partial dependence plots (PDP in GBM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next, user selects pipeline, final model is fit and ready for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
