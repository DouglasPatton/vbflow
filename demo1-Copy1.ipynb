{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from sys import getsizeof\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#Turn off warnings because hyper-parameter tuning will test many poor performing models\n",
    "from sys import warnoptions\n",
    "from warnings import simplefilter\n",
    "import os\n",
    "if not warnoptions:\n",
    "    simplefilter(\"ignore\")\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "420"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vb_helper import VBHelper\n",
    "\n",
    "kwargs=dict(\n",
    "    shuffle=True,\n",
    "    drop_duplicates='Xy',#'X',False\n",
    "    nan_threshold=0.9,#drop any column with more than this share of nulls\n",
    "    run_stacked=False, \n",
    "    test_share=0,\n",
    "    cv_folds=5,\n",
    "    cv_reps=1 ,\n",
    "    cv_strategy=None,# ('quantile',5), ('uniform',5) # (stratification method, groupcount)\n",
    "    )\n",
    "vbhelper=VBHelper(**kwargs)\n",
    "getsizeof(pickle.dumps(vbhelper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices for predictions: ['420', '652', '575', '89', '23', '19', '2', '273', '495', '585']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "420"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data\n",
    "data_path=os.path.join('sample_data','ex1.csv')\n",
    "df=pd.read_csv(data_path)\n",
    "df.index=[str(i) for i in df.index]\n",
    "#select variables\n",
    "y_name='THG_Fish'\n",
    "loc_vars=['LAT','LONG']\n",
    "drop_vars=['Date','OrigHabCode','STA_ID']\n",
    "drop_vars.extend(loc_vars)\n",
    "drop_vars.append(y_name)\n",
    "all_vars=list(df.columns)\n",
    "x_vars=[var for var in all_vars if var not in drop_vars]\n",
    "\n",
    "#extract random rows for prediction\n",
    "predict_n=10\n",
    "shuf=np.arange(df.shape[0])\n",
    "seed=0\n",
    "rng = np.random.default_rng(seed)\n",
    "rng.shuffle(shuf)\n",
    "predict_select=shuf[:predict_n]\n",
    "X_predict=df.loc[:,x_vars].iloc[predict_select]\n",
    "y_predict=df.loc[:,y_name].iloc[predict_select]\n",
    "predict_loc=[df.index[i] for i in predict_select]\n",
    "df.drop(index=predict_loc,inplace=True)\n",
    "X_df=df.loc[:,x_vars]\n",
    "y_df=df.loc[:,[y_name]]\n",
    "print(f'indices for predictions: {X_predict.index.to_list()}')\n",
    "getsizeof(pickle.dumps(vbhelper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "scorer_list=['neg_mean_squared_error', 'neg_mean_absolute_error', 'r2'] #strings defined in scikit-learn\n",
    "vbhelper.scorer_list=scorer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(764, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of duplicate rows of data: 0\n",
      "# of duplicate rows of X: 0\n",
      "# of duplicate Xy rows dropped: 0\n",
      "no columns exceeded nan threshold of 0.9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "273064"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vbhelper.setData(X_df,y_df)\n",
    "getsizeof(pickle.dumps(vbhelper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "inner_cv_dict={\n",
    "    'cv_reps':3,\n",
    "    'cv_folds':5,\n",
    "    'cv_strategy':('quantile',5)} # ensure each fold has y values from each quantile\n",
    "inner_cv=vbhelper.getCV(cv_dict=inner_cv_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "prep_dict={\n",
    "    'cat_approach':'together', # imputation is over all variables after one-hot-encoding\n",
    "    'impute_strategy':'IterativeImputer', # python implementation of MICE: Multivariate Imputation by Chained Equations in R‚Äù\n",
    "    'cat_idx':vbhelper.cat_idx # keep track of the categorical variables\n",
    "    }\n",
    "pipe_dict={} # the pipeline setup will go here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pipe_kwargs={\n",
    "    'do_prep':not vbhelper.run_stacked, # the stacking regressor will do imputation if run_stacked==True\n",
    "    'prep_dict':prep_dict,\n",
    "    'inner_cv':inner_cv,\n",
    "    'cat_idx':vbhelper.cat_idx,\n",
    "    'float_idx':vbhelper.float_idx,\n",
    "    'bestT':False # if true, test each covariate for optimal transformation \n",
    "    }"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "from vb_estimators import FlexibleGLM\n",
    "\n",
    "glm_kwargs=pipe_kwargs.copy()\n",
    "glm_kwargs['gridpoints']=5\n",
    "\n",
    "pipe_dict['GLM']={'pipe':FlexibleGLM,'pipe_kwargs':glm_kwargs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vb_torch import TorchNet\n",
    "\n",
    "torch_kwargs=pipe_kwargs.copy()\n",
    "torch_kwargs.pop('bestT')\n",
    "torch_kwargs['epochs']=1000\n",
    "torch_kwargs['batch_size']=64\n",
    "torch_kwargs['inner_cv']=None\n",
    "pipe_dict['torch_net']={'pipe':TorchNet,'pipe_kwargs':torch_kwargs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from vb_estimators import GBR\n",
    "\n",
    "gbr_kwargs=pipe_kwargs.copy()\n",
    "gbr_kwargs['est_kwargs']={\n",
    "    'n_estimators':[64,128],\n",
    "    'max_depth':[2,3]\n",
    "    }\n",
    "pipe_dict['gbr']={\n",
    "    'pipe':GBR,\n",
    "    'pipe_kwargs':gbr_kwargs\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from vb_estimators import  L1Lars\n",
    "\n",
    "l1_kwargs=pipe_kwargs.copy()\n",
    "l1_kwargs['max_n_alphas']=500 # alpha is the only hyper-parameter\n",
    "pipe_dict['lassolars']={\n",
    "    'pipe':L1Lars,\n",
    "    'pipe_kwargs':l1_kwargs\n",
    "    }"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "from vb_estimators import RBFSVR\n",
    "\n",
    "rbf_kwargs=pipe_kwargs.copy()\n",
    "rbf_kwargs['gridpoints']=5 \n",
    "pipe_dict['rbfSVR']={\n",
    "    'pipe':RBFSVR,\n",
    "    'pipe_kwargs':rbf_kwargs\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom vb_estimators import FlexiblePipe\\n\\nnl_pipe_kwargs=pipe_kwargs.copy()\\nnl_pipe_kwargs['functional_form_search']=True\\nnl_pipe_kwargs['flex_kwargs']={'robust':True}\\npipe_dict['nonlinear']={\\n    'pipe':FlexiblePipe,\\n    'pipe_kwargs':nl_pipe_kwargs\\n}\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from vb_estimators import FlexiblePipe\n",
    "\n",
    "nl_pipe_kwargs=pipe_kwargs.copy()\n",
    "nl_pipe_kwargs['functional_form_search']=True\n",
    "nl_pipe_kwargs['flex_kwargs']={'robust':True}\n",
    "pipe_dict['nonlinear']={\n",
    "    'pipe':FlexiblePipe,\n",
    "    'pipe_kwargs':nl_pipe_kwargs\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274190\n",
      "274533\n"
     ]
    }
   ],
   "source": [
    "#and load the pipelines\n",
    "vbhelper.setPipeDict(pipe_dict)\n",
    "print(getsizeof(pickle.dumps(vbhelper)))\n",
    "vbhelper.setModelDict()\n",
    "print(getsizeof(pickle.dumps(vbhelper)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from time import time\n",
    "X_train, X_test, y_train, y_test=train_test_split(X_df,y_df,test_size=0.5,random_state=5) #just for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch_net\n",
      "TorchTuner setting up round: 0.\n",
      "r:0. 0,1,2,3,4,r:0. 0,1,2,3,4,r:0. 0,1,2,3,4,r:0. 0,1,2,3,4,r:0. 0,1,2,3,4,r:0. 0,1,2,3,4,r:0. 0,1,2,3,4,r:0. 0,1,2,3,4,TorchTuner setting up round: 1.\n",
      "round: 1 losses: [(10532.255032031038, (0, 2), 2), (11495.154928175583, (0, 2), 4), (12117.737510235786, (0, 0), 7), (13104.197408749287, (0, 2), 1)]\n",
      "tt has setup round : 1 and the best model loss so far is: 10532.255032031038\n",
      "r:1. 0,1,2,3,4,r:1. 0,1,2,3,4,TorchTuner setting up round: 2.\n",
      "round: 2 losses: [(10532.255032031038, (0, 2), 2), (10887.694866242235, (1, 1), 4)]\n",
      "tt has setup round : 2 and the best model loss so far is: 10532.255032031038\n",
      "r:2. 0,1,2,3,4,TorchTuner setting up round: 3.\n",
      "round: 3 losses: [(10532.255032031038, (0, 2), 2)]\n",
      "tt has setup round : 3 and the best model loss so far is: 10532.255032031038\n",
      "r:3. 0,1,2,3,4,TorchTuner setting up round: 4.\n",
      "round: 4 losses: []\n",
      "all models cut\n",
      "train R2: 0.6021125636380484\n",
      "test R2: 0.4085520092447201\n",
      "runtime:7.256351280212402 min.\n",
      "\n",
      "gbr\n",
      "train R2: 0.8794403038094014\n",
      "test R2: 0.373426598476695\n",
      "runtime:0.2076821009318034 min.\n",
      "\n",
      "lassolars\n",
      "train R2: 0.446464001155798\n",
      "test R2: 0.3725404363518612\n",
      "runtime:0.010473636786142985 min.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "runtest=True\n",
    "if runtest:\n",
    "    for name,est in vbhelper.model_dict.items():\n",
    "        start=time()\n",
    "        print(name)\n",
    "        est.fit(X_train,y_train)\n",
    "        print('train R2:',est.score(X_train,y_train))\n",
    "        if not X_test is None:print('test R2:',est.score(X_test,y_test))\n",
    "        end=time()\n",
    "        print(f'runtime:{(end-start)/60} min.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "halt",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_137527/1365543486.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'halt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: halt"
     ]
    }
   ],
   "source": [
    "assert False,'halt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "if vbhelper.run_stacked and runtest:\n",
    "    mp=vbhelper.model_dict['stacking_reg']\n",
    "    fitted_ipipe_dict=mp.build_individual_fitted_pipelines()\n",
    "    for p_name,p in fitted_ipipe_dict.items():\n",
    "        print(f'{p_name} scored: {p.score(X_test,y_test)}')\n",
    "    print(getsizeof(pickle.dumps(vbhelper))/1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "vbhelper.runCrossValidate(try_load=False)\n",
    "print(getsizeof(pickle.dumps(vbhelper))/1e6)\n",
    "#del vbhelper.model_dict\n",
    "#print(getsizeof(pickle.dumps(vbhelper))/1e6)\n",
    "#del vbhelper.pipe_dict\n",
    "#print(getsizeof(pickle.dumps(vbhelper))/1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "vbhelper.buildCVScoreDict()\n",
    "vbhelper.saveCVResults()\n",
    "print(getsizeof(pickle.dumps(vbhelper))/1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(getsizeof(pickle.dumps(vbhelper.cv_results))/1e6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from vb_plotter import VBPlotter\n",
    "plotter=VBPlotter()\n",
    "\n",
    "with open('project_cv_results.json','rb') as f:\n",
    "    cv_results_and_scores=json.load(f)\n",
    "plotter.setData(cv_results_and_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter.plotCVYhatVsY(single_plot=True,include_all_cv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plotter.plotCVYhat(single_plot=True,include_all_cv=True) #add option to use original row order instead of sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plotter.plotCVScores(sort=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plotter.plotBoxWhiskerCVScores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# VB web\n",
    "## Small Data Procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Task 2: Train the Final, Predictive Model\n",
    "##### Using all of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "vbhelper.refitPredictiveModel(selected_model='torch_net',try_load=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# VB web\n",
    "## Small Data Procedure\n",
    "### Predict Phase\n",
    "Finally we are ready to use the predictive model that we just estimated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "vbhelper.predictandSave(X_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "with open('project_prediction_results.json', 'r') as f:\n",
    "    project_prediction_results=json.load(f)\n",
    "plotter.setPredictData(project_prediction_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "p_kwargs=dict(single_plot=True, include_all_cv=True,\n",
    "              ypredict=True,cv_ypredict=True,estimators='selected',prediction_interval=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separately plot each prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plotters=[VBPlotter() for _ in range(predict_n)]\n",
    "for p in plotters: p.setData(cv_results_and_scores)\n",
    "for i in range(predict_n): plotters[i].setPredictData(project_prediction_results,loc_row=y_predict.index[i])\n",
    "for i in range(predict_n): plotters[i].plotCVYhatVsY(**p_kwargs,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### And redraw the plots with the known values of y as vertical lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "p_kwargs['cv_ypredict']=True #\n",
    "plotters=[VBPlotter() for _ in range(predict_n)]\n",
    "for p in plotters: p.setData(cv_results_and_scores)\n",
    "for i in range(predict_n): plotters[i].setPredictData(project_prediction_results,loc_row=y_predict.index[i])\n",
    "for i in range(predict_n): plotters[i].plotCVYhatVsY(**p_kwargs,true_y=y_predict.loc[[y_predict.index[i]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
