{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/doug/miniconda3/envs/vbflow39/lib/python3.9/site-packages/sklearn/experimental/enable_hist_gradient_boosting.py:16: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from vb_estimators import  LinRegSupreme,LinSVR,RBFSVR,ENet,L1Lars,GBR,HGBR,FlexiblePipe\n",
    "from vb_helper import VBHelper\n",
    "from vb_cross_validator import regressor_q_stratified_cv\n",
    "from missing_val_transformer import missingValHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup the experiment/project\n",
    "#### note the 'run_stacked' kwarg that can be set to create the stacked_regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridpoints=5\n",
    "kwargs=dict(\n",
    "    run_stacked=True,\n",
    "    test_share=0,#keep at 0 for small datasets\n",
    "    cv_folds=5,\n",
    "    cv_reps=10,\n",
    "    #cv_groupcount=5,\n",
    "    cv_strategy=('quantile',5), # for stratified cv\n",
    "    random_state=2 # random_state for reproducibility\n",
    ")\n",
    "vbhelper=VBHelper(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer_list=['neg_mean_squared_error', 'neg_mean_absolute_error', 'r2'] #cross_validate wants strings\n",
    "vbhelper.scorer_list=scorer_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### User Import Dataset Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['STA_ID', 'LONG', 'LAT', 'OrigHabCode', 'Date', 'THG_Fish', 'YEAR', 'SEASON', 'SUBAREA', 'HABCODE', 'Floc_Depth_ft', 'AFDW_Floc', 'MEHG_Floc', 'THG_floc', 'Tot_Phos_floc', 'Bulk_Dens_Floc', 'Soil_Thickness_FT', 'AFDW_Soil', 'Bulk_Dens_Soil', 'PH_soil', 'SO4_soil', 'MEHG_soil', 'THG_soil', 'Tot_Carbon_Soil_%', 'Tot_Nitrogen_Soil_%', 'Tot_Phos_soil', 'Wat_Depth_ft', 'COND_SW', 'DO_SW', 'TEMP_SW', 'PH_SW', 'TURB_SW', 'REDOX_SW', 'Alk_Phos_SW', 'CHLA_SW', 'CL_SW', 'MEHG_SW', 'NH4_SW', 'NO2_SW', 'NO3_SW', 'SO4_SW', 'Sol_Reac_Phos_SW', 'THG_SW', 'TOC_SW', 'Tot_Nitrogen_SW', 'Tot_Phos_SW', 'REDOX_PW', 'H2S_PW', 'Sol_Reac_Phos_PW', 'MEHG_Peri_AVG', 'THG_epi_peri']\n"
     ]
    }
   ],
   "source": [
    "data_path=os.path.join('sample_data','ex1.csv')\n",
    "df=pd.read_csv(data_path)\n",
    "all_vars=list(df.columns)\n",
    "print(all_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### user has option to specify \"regulatory standard\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "data_path=os.path.join('sample_data','ex1.csv')\n",
    "df=pd.read_csv(data_path)\n",
    "\n",
    "#select variables\n",
    "y_name='THG_Fish'\n",
    "loc_vars=['LAT','LONG']\n",
    "drop_vars=['Date','OrigHabCode','STA_ID']\n",
    "drop_vars.extend(loc_vars)\n",
    "drop_vars.append(y_name)\n",
    "all_vars=list(df.columns)\n",
    "x_vars=[var for var in all_vars if var not in drop_vars]\n",
    "\n",
    "#extract random rows for prediction\n",
    "predict_n=3\n",
    "shuf=np.arange(df.shape[0])\n",
    "seed=0\n",
    "rng = np.random.default_rng(seed)\n",
    "rng.shuffle(shuf)\n",
    "predict_select=shuf[:predict_n]\n",
    "X_predict=df.loc[:,x_vars].iloc[predict_select].copy()\n",
    "y_predict=df.loc[:,y_name].iloc[predict_select].copy()\n",
    "df.drop(index=predict_select,inplace=True)\n",
    "X_df=df.loc[:,x_vars]\n",
    "y_df=df.loc[:,[y_name]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of duplicate rows of data: 0\n",
      "# of duplicate rows of X: 0\n",
      "no columns exceeded nan threshold of 0.99\n"
     ]
    }
   ],
   "source": [
    "vbhelper.setData(X_df,y_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup the analytical pipelines\n",
    "#### note the inner_cv_dict and prep_dict that are used to consolidate vb_estimator kwargs and to facilitate the divison between prep and post steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "inner_cv_dict={\n",
    "    'cv_reps':1,\n",
    "    'cv_folds':5,\n",
    "    'cv_strategy':('quantile',5)} # ensure each fold has y values from each quantile\n",
    "inner_cv=vbhelper.getCV(cv_dict=inner_cv_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### specify data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "prep_dict={\n",
    "    'cat_approach':'together', # imputation is over all variables after one-hot-encoding\n",
    "    'impute_strategy':'IterativeImputer', # python implementation of MICE: Multivariate Imputation by Chained Equations in R‚Äù\n",
    "    'cat_idx':vbhelper.cat_idx # keep track of the categorical variables\n",
    "    }\n",
    "pipe_dict={} # the pipeline setup will go here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### specify pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "##### setup keyword arguments for pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pipe_kwargs={\n",
    "    'do_prep':not vbhelper.run_stacked, # the stacking regressor will do imputation if run_stacked==False\n",
    "    'prep_dict':prep_dict,\n",
    "    'inner_cv':inner_cv,\n",
    "    'cat_idx':vbhelper.cat_idx,\n",
    "    'float_idx':vbhelper.float_idx,\n",
    "    'bestT':False # if true, test each covariate for optimal transformation \n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "##### create a cross-validated lasso linear regression pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from vb_estimators import  L1Lars\n",
    "\n",
    "l1_kwargs=pipe_kwargs.copy()\n",
    "l1_kwargs['max_n_alphas']=500 # alpha is the only hyper-parameter\n",
    "pipe_dict['lassolars']={\n",
    "    'pipe':L1Lars,\n",
    "    'pipe_kwargs':l1_kwargs\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### and a gradient boosting regressor pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from vb_estimators import GBR\n",
    "\n",
    "gbr_kwargs=pipe_kwargs.copy()\n",
    "gbr_kwargs['est_kwargs']={\n",
    "    'n_estimators':[64,128],\n",
    "    'max_depth':[2,3]\n",
    "    }\n",
    "pipe_dict['gbr']={\n",
    "    'pipe':GBR,\n",
    "    'pipe_kwargs':gbr_kwargs\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### and a gradient boosting regressor pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from vb_estimators import RBFSVR\n",
    "\n",
    "rbf_kwargs=pipe_kwargs.copy()\n",
    "rbf_kwargs['gridpoints']=5 \n",
    "pipe_dict['rbfSVR']={\n",
    "    'pipe':RBFSVR,\n",
    "    'pipe_kwargs':rbf_kwargs\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "and finally add a pipeline that tests a few non-linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from vb_estimators import FlexiblePipe\n",
    "\n",
    "nl_pipe_kwargs=pipe_kwargs.copy()\n",
    "nl_pipe_kwargs['functional_form_search']=True\n",
    "nl_pipe_kwargs['flex_kwargs']={'robust':True}\n",
    "pipe_dict['nonlinear']={\n",
    "    'pipe':FlexiblePipe,\n",
    "    'pipe_kwargs':nl_pipe_kwargs\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#and load the pipelines\n",
    "vbhelper.setPipeDict(pipe_dict)\n",
    "vbhelper.setModelDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jhash:  c745fd30f1b75d8e71dc016088151bb6\n"
     ]
    }
   ],
   "source": [
    "start=time()\n",
    "vbhelper.runCrossValidate(try_load=True)\n",
    "end=time()\n",
    "print(f'runtime:{(end-start)/60} min.\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Fit the final models for all estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vbhelper.refitPredictiveModels(selected_models=['stacking_reg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat=vbhelper.predict(X_predict)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(yhat['prediction']['r2']-y_predict)/y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_cv=vbhelper.predict(X_predict,model_type='cross_validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
