{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.pipeline import make_pipeline,Pipeline\n",
    "from sklearn.linear_model import ElasticNetCV, LinearRegression, Lars,LassoLarsCV\n",
    "from sklearn.svm import LinearSVR, SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_validate, train_test_split, RepeatedKFold, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, train_test_split, RepeatedKFold, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#sys.path.append(os.path.abspath('..'))#sys.path[0] + '/..') \n",
    "from vb_estimators import LinRegSupreme,LinSVR,RBFSVR,ENet,L1Lars\n",
    "from vb_helper import VBHelper\n",
    "from vb_cross_validator import regressor_q_stratified_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridpoints=5\n",
    "test_share=0.2\n",
    "cv_folds=5\n",
    "cv_reps=3\n",
    "cv_count=cv_folds*cv_reps\n",
    "group_count=5 # for stratified cv\n",
    "rs=1 # random_state for reproducibility\n",
    "vbhelper=VBHelper(test_share,cv_folds,cv_reps,cv_count,rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer_list=['neg_mean_squared_error', 'neg_mean_absolute_error', 'r2'] #cross_validate wants strings\n",
    "#cv=RepeatedKFold(n_splits=cv_folds, n_repeats=cv_reps, random_state=rs) # define separately to ensure same cv data used for each model\n",
    "cv=regressor_q_stratified_cv(n_splits=cv_folds, n_repeats=cv_reps, random_state=rs,group_count=group_count,strategy='quantile')\n",
    "\n",
    "vbhelper.scorer_list=scorer_list\n",
    "# allow/generate water quality thresholds for stratified kfold sub-sampling to ensure cross-validation folds have full range of water quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=os.path.join('sample_data','ex1.csv')\n",
    "df=pd.read_csv(data_path)\n",
    "all_vars=list(df.columns)\n",
    "print(all_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_name='THG_Fish'\n",
    "loc_vars=['LAT','LONG']\n",
    "drop_vars=['Date','OrigHabCode','STA_ID']\n",
    "drop_vars.extend(loc_vars)\n",
    "drop_vars.append(y_name)\n",
    "x_vars=[var for var in all_vars if var not in drop_vars]\n",
    "X_df=df.loc[:,x_vars]\n",
    "y_df=df.loc[:,y_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "shuf=np.arange(y_df.shape[0])\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(shuf)\n",
    "X_df=X_df.iloc[shuf]\n",
    "y_df=y_df.iloc[shuf]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size=test_share,random_state=rs)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_idx,cat_vars=zip(*[(i,var) for i,(var,dtype) in enumerate(dict(X_train.dtypes).items()) if dtype=='object'])\n",
    "float_idx=[i for i in range(X_train.shape[1]) if i not in cat_idx]\n",
    "print(cat_idx,cat_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_kwargs=dict(gridpoints=gridpoints,cat_idx=cat_idx,float_idx=float_idx,bestT=False)\n",
    "estimator_dict={\n",
    "    'lin-reg-supreme':lambda: LinRegSupreme(**est_kwargs),\n",
    "    'elastic-net':lambda: ENet(**est_kwargs), \n",
    "    'linear-svr-cv':lambda: LinSVR(**est_kwargs), \n",
    "    'rbf-svr-cv':lambda: RBFSVR(**est_kwargs), \n",
    "    'lassolars':lambda: L1Lars(**est_kwargs),\n",
    "    #'HistGradientBoostingRegressor':HistGradientBoostingRegressor,\n",
    "    #'gradient-boosting-reg':gradient_boosting_reg(bestT=True)\n",
    "   }\n",
    "vbhelper.estimator_dict=estimator_dict\n",
    "model_dict={key:val() for key,val in estimator_dict.items()} # they will be models once .fit is called"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for name,est in model_dict.items():\n",
    "    start=time()\n",
    "    i+=1;print(name)\n",
    "    est.fit(X_train,y_train)\n",
    "    print('train R2:',est.score(X_train,y_train))\n",
    "    if not X_test is None:print('test R2:',est.score(X_test,y_test))\n",
    "    end=time()\n",
    "    print(f'runtime:{(end-start)/60} min.\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_kwargs=dict(gridpoints=gridpoints,cat_idx=cat_idx,float_idx=float_idx,bestT=True)\n",
    "estimator_dict={\n",
    "    'lin-reg-supreme':lambda: LinRegSupreme(**est_kwargs),\n",
    "    'elastic-net':lambda: ENet(**est_kwargs), \n",
    "    'linear-svr-cv':lambda: LinSVR(**est_kwargs), \n",
    "    'rbf-svr-cv':lambda: RBFSVR(**est_kwargs), \n",
    "    'lassolars':lambda: L1Lars(**est_kwargs),\n",
    "    #'gradient-boosting-reg':gradient_boosting_reg(bestT=True)\n",
    "   }\n",
    "vbhelper.estimator_dict=estimator_dict\n",
    "model_dict={key:val() for key,val in estimator_dict.items()} # they will be models once .fit is called"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for name,est in model_dict.items():\n",
    "    start=time()\n",
    "    i+=1;print(name)\n",
    "    est.fit(X_train,y_train)\n",
    "    print('train R2:',est.score(X_train,y_train))\n",
    "    if not X_test is None:print('test R2:',est.score(X_test,y_test))\n",
    "    end=time()\n",
    "    print(f'runtime:{(end-start)/60} min.\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results={}\n",
    "for estimator_name,model in model_dict.items():\n",
    "    start=time()\n",
    "    model_i=cross_validate(model, X_df, y_df, return_estimator=True, scoring=scorer_list, cv=cv, n_jobs=4)\n",
    "    end=time()\n",
    "    print(f\"{estimator_name},{[(scorer,np.mean(model_i[f'test_{scorer}'])) for scorer in scorer_list]}, runtime:{(end-start)/60} min.\")\n",
    "    cv_results[estimator_name]=model_i\n",
    "            \n",
    "# replace with a loop in order to save the residuals for a graph?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### graphs and table to summarize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_score_dict={}\n",
    "cv_score_dict_means={}\n",
    "for idx,(estimator_name,result) in enumerate(cv_results.items()):\n",
    "    #cv_estimators=result['estimator']\n",
    "    model_idx_scoredict={scorer:result[f'test_{scorer}'] for scorer in scorer_list}# fstring bc how cross_validate stores list of metrics\n",
    "    cv_score_dict[estimator_name]=model_idx_scoredict \n",
    "    model_idx_mean_scores={scorer:np.mean(scores) for scorer,scores in model_idx_scoredict.items()}\n",
    "    cv_score_dict_means[estimator_name]=model_idx_mean_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scorer in scorer_list:\n",
    "    print(f'scores for scorer: {scorer}:')\n",
    "    for estimator_name in model_dict:\n",
    "        print(f'    {estimator_name}:{cv_score_dict_means[estimator_name][scorer]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vbhelper.plotCVScores(cv_score_dict,sort=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
