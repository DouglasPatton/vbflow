{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.pipeline import make_pipeline,Pipeline\n",
    "from sklearn.linear_model import ElasticNetCV, LinearRegression, Lars, ElasticNet\n",
    "from sklearn.svm import LinearSVR, SVR\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer, PolynomialFeatures\n",
    "from sklearn.model_selection import cross_validate, train_test_split, RepeatedKFold, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from vb_helper import VBHelper,shrinkBigKTransformer,logminus_T,exp_T,logminplus1_T,none_T, logp1_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Data Analytics Acceleration Library (Intel(R) DAAL) solvers for sklearn enabled: https://intelpython.github.io/daal4py/sklearn.html\n"
     ]
    }
   ],
   "source": [
    "import daal4py.sklearn\n",
    "daal4py.sklearn.patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_share=0.2 \n",
    "cv_folds=10\n",
    "cv_reps=10\n",
    "cv_count=cv_folds*cv_reps\n",
    "rs=1 # random_state for reproducibility\n",
    "vbhelper=VBHelper(test_share,cv_folds,cv_reps,cv_count,rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n",
      "[ 5.92204312  8.50829925  9.29127265 11.68951601  9.12258936  5.49719264\n",
      " 14.3562217   9.24413212  5.49112774 18.61125476  7.56701548 13.5675252\n",
      "  7.28330449  6.11116954 10.19300877 12.47879443 17.83837868  8.24769078\n",
      " 10.86826015  8.832442   15.02564369  7.59370547  9.01252021  7.39590944\n",
      " 12.61375     5.38415542  5.75039776  9.25207432 10.13815771  7.50420653\n",
      " 14.46515236  7.40392825  8.35857582  4.8762096  11.81714571  9.62465031\n",
      " 16.72547231 13.34529152  9.21522548 11.29091934 11.14484074  8.40199541\n",
      "  6.41762653 10.69788092  4.96805857  9.58393763  6.38961059 14.36975938\n",
      "  6.84925263  7.47084725  9.88212888 12.09678597  7.79288779 14.75374146\n",
      "  5.81990046 14.76559453  7.74378062  5.15092576  4.49746358  8.90075735\n",
      "  7.96764892  7.52072818  7.13820281 10.54947602 21.81560383  3.66825392\n",
      "  9.08647989 11.77309092  5.55925765  6.18225542  8.48883634  9.71042079\n",
      " 13.06677646  8.63463203 15.6807087   9.69461892 13.04265622  5.49081403\n",
      "  6.96509038  9.90620466  9.76921876  8.23196792  6.18800458  4.22256432\n",
      "  6.39624371  7.32389154 13.91976287 11.54233827  7.95372216  6.20559331\n",
      " 11.61777757 11.3423452   8.10259806  8.43607525  8.45961337 12.20504107\n",
      "  7.10583142 14.32112731  6.36719914  4.6506791  10.53104681 12.63695053\n",
      "  7.86547101  8.32829865  4.08909431 10.48547917  4.81232631  5.62955291\n",
      "  8.4655437   9.72529626 21.81173764  9.40508764 15.5734435   5.80057159\n",
      "  7.46257924  5.91870737 15.32050998  6.89914847 10.50224417 11.69014461\n",
      "  6.26653815  4.65084613 12.22983371  2.71828183  9.92810277  4.63133848\n",
      " 19.2827559   8.45647569 12.2300446   6.95334813  9.20973223 12.76968762\n",
      "  6.88967376  8.28551305  9.27715853  6.56463121 10.72456879  9.88511383\n",
      "  8.65075194  7.84356052  4.61402669  8.4703218  10.01849283  9.63397143\n",
      "  5.73643923  6.21574441 12.59599989  7.79288903 10.6325754   5.15841914\n",
      "  9.01611232  5.56648224 18.5852567   9.29713321  9.16361686  7.65208173\n",
      "  8.27766918 11.79601863 14.57359659  7.74873862  6.45720746  8.8473346\n",
      "  8.70626239 16.28506863  7.15020672 12.8964986   5.86850231  9.55077612\n",
      " 14.47438318  8.05806007  5.70637687  7.53347176  3.9794939   3.41772385\n",
      "  5.70070934  7.18855141  5.61567799  7.71206114  9.34699484  8.49158949\n",
      " 18.73629545 12.09194059  5.65620216  9.62853246 10.54780255  5.32674654\n",
      "  9.98424759 15.2414372   7.88232282  4.40592266 14.38453989  9.95497949\n",
      "  5.86889462  6.21980193 10.22326157 11.18632437 12.94456187  8.71426808\n",
      "  4.3115781  10.25262224 12.17835544  9.01628789  6.498688    7.58565401\n",
      "  6.38957049  9.65837699  7.75368683  8.39146097  6.91180581  6.21331693\n",
      "  9.35715805 12.87873481 11.20812759  7.79551241  9.05149096  6.90982415\n",
      "  6.16552646 12.69603268  4.87162254  5.9360697   6.68523919 10.98854365\n",
      "  9.30515712 10.98800961  7.7767214   9.91303546  9.38814336  7.97978337\n",
      "  4.59892039  7.83068254  7.96904293 11.97350294  8.43909981 12.72417099\n",
      " 14.39287592 11.2430335   8.24136027  5.95364425  9.42122456 13.47415772\n",
      "  5.62706884  5.34773554 12.10668407  5.35615938  9.96224298 17.08769659\n",
      " 14.81586774  9.91464003  9.92271972  8.46151339 10.26062857  4.90004501\n",
      "  7.31753678 10.83879145  5.22371948  8.20610123  5.73165778  3.57088871\n",
      "  4.32674213  7.89386255 15.46437174  6.08479138 16.16249533  7.20561657\n",
      "  7.7604775   8.21921616  6.48527535  7.30778708  8.00342097  7.88718399\n",
      "  7.3784561   7.27870866 11.15638035 10.37290345 15.95885143  5.62074264\n",
      " 14.06435294 11.02424951  7.36634722  6.14348215  7.88078861 16.38654752\n",
      " 13.69274381 10.97316032  8.47866609  8.76113887 13.42535055  8.61627704\n",
      "  8.46951062  5.95406929  3.43563824 10.37378254  8.52425477  6.80034754\n",
      "  4.02866827  8.52189132  9.67661553  5.39082828 10.64896818  6.04735435]\n"
     ]
    }
   ],
   "source": [
    "X, y, w = make_regression(n_samples=300,\n",
    "                          n_features=8, # x variables generated and returned \n",
    "                          n_informative=2, # x variables included in the actual model of y\n",
    "                          effective_rank=2, # make less than n_informative for multicollinearity\n",
    "                          coef=True,\n",
    "                          noise=3,\n",
    "                          random_state=rs,\n",
    "                          bias=1)\n",
    "\n",
    "#xt=np.product(X[:,0:2],axis=-1)\n",
    "for i in range(1,5,5):\n",
    "    sgn_mult=3**i*(-1)**i\n",
    "    y+=sgn_mult*np.product(10*X[:,i:i+2],axis=-1)\n",
    "print(y.shape)\n",
    "#xtnorm=xt/np.sum(xt)\n",
    "#print(xtnorm.shape)\n",
    "y=np.exp((y-np.min(y))/10+1)\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add interaction terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_share:\n",
    "     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_share, random_state=rs)\n",
    "else:\n",
    "    X_train, X_test, y_train, y_test = (X, None, y, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n,k=X_train.shape\n",
    "\n",
    "max_k=n//2\n",
    "\n",
    "vbhelper.max_k=max_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use lambda to make a callable object for creating new models, but with args set already\n",
    "# may be unnecessary due to sklearn cloning\n",
    "\n",
    "\n",
    "linear_regression=lambda: make_pipeline(StandardScaler(),LinearRegression(fit_intercept=1)) \n",
    "linear_regression_lars=lambda: make_pipeline(StandardScaler(),shrinkBigKTransformer(max_k=max_k),LinearRegression()) #https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lars.html\n",
    "elastic_net =lambda: make_pipeline(StandardScaler(), ElasticNetCV())\n",
    "linear_svr =lambda: make_pipeline(StandardScaler(),LinearSVR(random_state=rs,tol=1e-4,max_iter=5000,C=1))\n",
    "rbf_svr=lambda: make_pipeline(StandardScaler(),SVR(kernel='rbf',tol=1e-4,max_iter=5000, C=1))\n",
    "gradient_boosting_reg=lambda: make_pipeline(GradientBoostingRegressor())\n",
    "\n",
    "g_pts=3 # grid points for gridsearchcv param_grid \n",
    "linear_svr = Pipeline(steps=[('scaler',StandardScaler()),('lin_svr',LinearSVR(random_state=0,tol=1e-4,max_iter=10000))])\n",
    "lin_svr_param_grid={'lin_svr__C':np.logspace(-2,2,g_pts)}\n",
    "linear_svr_cv=lambda: GridSearchCV(linear_svr,param_grid=lin_svr_param_grid)\n",
    "\n",
    "rbf_svr=Pipeline(steps=[('scaler',StandardScaler()),('rbf_svr',SVR(kernel='rbf',tol=1e-4,max_iter=10000, cache_size=2*10**3))])\n",
    "rbf_svr_param_grid={'rbf_svr__C':np.logspace(-2,2,g_pts),'rbf_svr__gamma':np.logspace(-1,0.5,g_pts)} \n",
    "rbf_svr_cv=lambda: GridSearchCV(rbf_svr,param_grid=rbf_svr_param_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_list=[none_T(),logp1_T ()]#[logminplus1_T(),none_T(),logminus_T()]#exp_T()] # imported...\n",
    "lin_reg_y_t_pipe=Pipeline(steps=[('ttr',TransformedTargetRegressor(regressor=linear_regression_lars()))])\n",
    "lin_reg_y_t_param_grid={'ttr__transformer':transformer_list}\n",
    "lin_reg_y_transform=lambda: GridSearchCV(lin_reg_y_t_pipe,param_grid=lin_reg_y_t_param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### add PolynomialFeatures() to gridsearch\n",
    "#### and try shrinking the number of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps=[\n",
    "    ('scaler',StandardScaler()),\n",
    "    #('shrink_k1',shrinkBigKTransformer(selector='elastic-net')), # retain a subset of the best original variables\n",
    "    ('polyfeat',PolynomialFeatures(interaction_only=1)), # create interactions among them\n",
    "    ('shrink_k2',shrinkBigKTransformer(selector='elastic-net')), # pick from all of those options\n",
    "    ('pca',PCA()),\n",
    "    ('reg',linear_regression())]\n",
    "\n",
    "inner_params={'polyfeat__degree':[2],\n",
    "                        'pca__n_components':np.logspace(np.log10(0.5),0,5,endpoint=False),\n",
    "                        }\n",
    "\n",
    "inner_cv=RepeatedKFold(n_splits=5, n_repeats=1, random_state=rs)\n",
    "X_T_pipe=GridSearchCV(Pipeline(steps=steps),param_grid=inner_params,cv=inner_cv)\n",
    "\n",
    " \n",
    "\n",
    "Y_T_X_T_pipe=Pipeline(steps=[('ttr',TransformedTargetRegressor(regressor=X_T_pipe))])\n",
    "Y_T__param_grid={'ttr__transformer':transformer_list}\n",
    "lin_reg_Xy_PCA_transform=lambda: GridSearchCV(Y_T_X_T_pipe,param_grid=Y_T__param_grid,cv=inner_cv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_dict={'linear-regression':linear_regression,\n",
    "                #'linear-regression-lars':linear_regression_lars,\n",
    "                #'lin_reg_y_transform':lin_reg_y_transform,\n",
    "                'lin_reg_Xy_PCA_transform':lin_reg_Xy_PCA_transform,\n",
    "                'elastic-net':elastic_net, }\n",
    "                #'linear-svr-cv':linear_svr_cv, }\n",
    "                #'rbf-svr-cv':rbf_svr_cv, \n",
    "                #'gradient-boosting-reg':gradient_boosting_reg}\n",
    "vbhelper.estimator_dict=estimator_dict\n",
    "model_dict={key:val() for key,val in estimator_dict.items()} # they will be models once .fit is called"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer_list=['neg_mean_squared_error', 'neg_mean_absolute_error', 'r2'] #cross_validate wants strings\n",
    "cv=RepeatedKFold(n_splits=cv_folds, n_repeats=cv_reps, random_state=rs) # define separately to ensure same cv data used for each model\n",
    "vbhelper.scorer_list=scorer_list\n",
    "# allow/generate water quality thresholds for stratified kfold sub-sampling to ensure cross-validation folds have full range of water quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple=[est.fit(X_train,y_train) for name,est in model_dict.items()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results={estimator_name:cross_validate(model, X_train, y_train, return_estimator=True, scoring=scorer_list, cv=cv)\n",
    "            for estimator_name,model in model_dict.items()}\n",
    "# replace with a loop in order to save the residuals for a graph?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### graphs and table to summarize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_score_dict={}\n",
    "cv_score_dict_means={}\n",
    "for idx,(estimator_name,result) in enumerate(cv_results.items()):\n",
    "    #cv_estimators=result['estimator']\n",
    "    model_idx_scoredict={scorer:result[f'test_{scorer}'] for scorer in scorer_list}# fstring bc how cross_validate stores list of metrics\n",
    "    cv_score_dict[estimator_name]=model_idx_scoredict \n",
    "    model_idx_mean_scores={scorer:np.mean(scores) for scorer,scores in model_idx_scoredict.items()}\n",
    "    cv_score_dict_means[estimator_name]=model_idx_mean_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scorer in scorer_list:\n",
    "    print(f'scores for scorer: {scorer}:')\n",
    "    for estimator_name in model_dict:\n",
    "        print(f'    {estimator_name}:{cv_score_dict_means[estimator_name][scorer]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vbhelper.plotCVScores(cv_score_dict,sort=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a similar plot showing residuals from the cv models for each value of y. \n",
    "# needs to be scatterplot or histogram since there will be (folds-1)*repeats predictions of each value of y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------\n",
    "### User chooses Linear Regression with LARS variable selection!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_estimator_name='linear-regression-lars'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printTestandCVScores(estimator_name,cv_score_dict_means):\n",
    "    model=estimator_dict[estimator_name]()\n",
    "    model.fit(X_train,y_train)\n",
    "    if test_share:\n",
    "        y_test_hat=model.predict(X_test)\n",
    "        print(f'test set: negative-mse={-mean_squared_error(y_test,y_test_hat)}')\n",
    "    for scorer in scorer_list:\n",
    "        print(f'cv avg: {scorer}= {cv_score_dict_means[estimator_name][scorer]}')\n",
    "    try:\n",
    "        print('coefficients: ',model[-1].coef_)\n",
    "        print('intercept: ',model[-1].intercept_)\n",
    "        #print('\\n','original positions: ',model[-2].col_select)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in estimator_dict.keys():\n",
    "    print(name)\n",
    "    printTestandCVScores(final_estimator_name,cv_score_dict_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printTestandCVScores('elastic-net',cv_score_dict_means)\n",
    "# fits better but soooo many coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printTestandCVScores('lin_reg_Xy_transform',cv_score_dict_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
